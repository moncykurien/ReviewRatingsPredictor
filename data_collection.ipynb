{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementNotInteractableException, ElementClickInterceptedException, TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "import time as t\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import os\n",
    "import shutil\n",
    "pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drive_launch(url):\n",
    "    \"\"\"\n",
    "    This function initiates the Chrome browser's driver with the url passed as a parameter and returns the driver instance.\n",
    "    Parameters:\n",
    "        url - url of the website\n",
    "    return:\n",
    "        driver - driver instance of the chrome browser    \n",
    "    \"\"\"\n",
    "    #creating driver instance\n",
    "    driver = webdriver.Chrome('./driver/chromedriver.exe')\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    #defining implicit wait\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #launching the url\n",
    "    driver.get(url)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_amazon(d, products):\n",
    "    ama_revs = []\n",
    "    ama_rats = []\n",
    "    for product in products:\n",
    "                d.find_element_by_id('twotabsearchtextbox').send_keys(product)\n",
    "                d.find_element_by_id('nav-search-submit-button').click()\n",
    "                plp_url = d.current_url\n",
    "                prods_elems = d.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none']//a[@class='a-link-normal a-text-normal']\")\n",
    "                main_window = d.current_window_handle\n",
    "                for i in range(0, len(prods_elems)):\n",
    "                    t.sleep(2)\n",
    "                    try:\n",
    "                        prods_elems[i].click()\n",
    "                    except StaleElementReferenceException:\n",
    "                        prods_elems = d.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none']//a[@class='a-link-normal a-text-normal']\")\n",
    "                        prods_elems[i].click()\n",
    "                    t.sleep(2)\n",
    "                    #get the window handles and switch to the new tab\n",
    "                    all_windows = d.window_handles\n",
    "                    d.switch_to.window(all_windows[1])\n",
    "                    t.sleep(2)\n",
    "                    try:\n",
    "                        d.find_element_by_xpath(\"//a[@data-hook='see-all-reviews-link-foot']\").click()\n",
    "                        t.sleep(2)\n",
    "                        while True:\n",
    "                            reviews = d.find_elements_by_xpath(\"//div[@class='a-row a-spacing-small review-data']\")\n",
    "                            ratings = d.find_elements_by_xpath(\"//div[@class='a-row a-spacing-small review-data']/..//div[@class='a-row']/a[@class='a-link-normal']\")\n",
    "                            for review, rating in zip(reviews, ratings):\n",
    "                                ama_revs.append(review.text)\n",
    "                                ama_rats.append(rating.get_attribute('title').split('.')[0])\n",
    "                            try:\n",
    "                                d.find_element_by_xpath(\"//a[contains(text(),'Next page')]\").click()\n",
    "                                t.sleep(2)\n",
    "                            except:\n",
    "                                break\n",
    "                    except NoSuchElementException:\n",
    "                        pass\n",
    "                    d.close()\n",
    "                    d.switch_to.window(main_window)\n",
    "    return ama_revs, ama_rats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_flipkart(d, products, no_pages):\n",
    "    flip_revs = []\n",
    "    flip_rats = []\n",
    "    fliprevs = []\n",
    "    fliprats = []\n",
    "    d.find_element_by_xpath(\"//button[contains(text(),'âœ•')]\").click()\n",
    "    t.sleep(1)\n",
    "    for product in products:\n",
    "                d.find_element_by_xpath(\"//input[@type='text']\").send_keys(product)\n",
    "                d.find_element_by_xpath(\"//button[@type='submit']\").click()\n",
    "                t.sleep(2)\n",
    "                plp_url = d.current_url\n",
    "                prods_elems = d.find_elements_by_xpath(\"//div[@class='_4rR01T']\")\n",
    "                main_window = d.current_window_handle\n",
    "                for i in range(0, len(prods_elems)):\n",
    "                    try:\n",
    "                        prods_elems[i].click()\n",
    "                    except StaleElementReferenceException:\n",
    "                        prods_elems = d.find_elements_by_xpath(\"//div[@class='_4rR01T']\")\n",
    "                        prods_elems[i].click()\n",
    "                    t.sleep(2)\n",
    "                    #get the window handles and switch to the new tab\n",
    "                    all_windows = d.window_handles\n",
    "                    d.switch_to.window(all_windows[1])\n",
    "                    try:\n",
    "                        d.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()\n",
    "                        t.sleep(2)\n",
    "                        counter = 0\n",
    "                        while counter < no_pages:\n",
    "                            reviews = d.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "                            ratings = d.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "                            read_mores = d.find_elements_by_xpath(\"//div[@class='t-ZTKy']//span[contains(text(),'READ MORE')]\")\n",
    "                            i = 0\n",
    "                            for review, rating in zip(reviews, ratings):\n",
    "                                try:\n",
    "                                    read_mores[i].click()\n",
    "                                except (ElementNotInteractableException,ElementClickInterceptedException, NoSuchElementException):\n",
    "                                    pass\n",
    "                                i += 1\n",
    "                                flip_revs.append(review.text)\n",
    "                                flip_rats.append(rating.text)\n",
    "                            try:\n",
    "                                d.find_element_by_xpath(\"//a/span[contains(text(),'Next')]\").click()\n",
    "                                t.sleep(2)\n",
    "                                counter += 1\n",
    "                            except:\n",
    "                                break\n",
    "                    except NoSuchElementException:\n",
    "                        pass\n",
    "                    d.close()\n",
    "                    d.switch_to.window(main_window)\n",
    "    return flip_revs, flip_rats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_snapdeal(d, products):\n",
    "    snap_revs = []\n",
    "    snap_rats = []\n",
    "    snaprevs = []\n",
    "    snaprats = []\n",
    "    for product in products:\n",
    "                d.find_element_by_id('inputValEnter').send_keys(product)\n",
    "                d.find_element_by_class_name('searchTextSpan').click()\n",
    "                plp_url = d.current_url\n",
    "                for i in range(3):\n",
    "                    try:\n",
    "                        d.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "                        t.sleep(2)\n",
    "                    except:\n",
    "                        break\n",
    "                    \n",
    "                try:\n",
    "                    d.find_element_by_xpath(\"//p[@class='goToTop']\").click()\n",
    "                except:\n",
    "                    pass\n",
    "                t.sleep(1)\n",
    "                \n",
    "                prods_elems = d.find_elements_by_xpath(\"//div[@class='product-desc-rating ']//div[@class='rating-stars ']\")\n",
    "                main_window = d.current_window_handle\n",
    "                for i in range(0, len(prods_elems)):\n",
    "                    t.sleep(2)\n",
    "                    try:\n",
    "                        prods_elems[i].click()\n",
    "                    except StaleElementReferenceException:\n",
    "                        prods_elems = d.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none']//a[@class='a-link-normal a-text-normal']\")\n",
    "                        prods_elems[i].click()\n",
    "                    t.sleep(2)\n",
    "                    #get the window handles and switch to the new tab\n",
    "                    all_windows = d.window_handles\n",
    "                    d.switch_to.window(all_windows[1])\n",
    "                    t.sleep(2)\n",
    "                    try:\n",
    "                        d.find_element_by_xpath(\"//span[@class='numbr-review']\").click()\n",
    "                        t.sleep(1)\n",
    "                        try:\n",
    "                            d.find_element_by_xpath(\"//a[@class='btnload LTgray reset-margin']\").click()\n",
    "                            t.sleep(2)\n",
    "                        except NoSuchElementException:\n",
    "                            pass\n",
    "                        except ElementClickInterceptedException:\n",
    "                            d.find_element_by_xpath(\"//a[@class='btnload LTgray reset-margin']\").click()\n",
    "                            t.sleep(2)\n",
    "                        while True:\n",
    "                            ratings = d.find_elements_by_xpath(\"//div[@class='commentreview']/div//div[@class='rating']\")\n",
    "                            review_heads = d.find_elements_by_xpath(\"//div[@class='commentreview']/div//div[@class='head']\")\n",
    "                            review_bodies = d.find_elements_by_xpath(\"//div[@class='user-review']//p\")\n",
    "                            \n",
    "                            for rating, review_head, review_body in zip(ratings, review_heads, review_bodies):\n",
    "                                r = rating\n",
    "                                stars = r.find_elements_by_xpath(\".//i[@class='sd-icon sd-icon-star active']\")\n",
    "                                snap_rats.append(len(stars))\n",
    "                                snap_revs.append(review_head.text+'.'+review_body.text)\n",
    "                            \n",
    "                            try:\n",
    "                                d.find_element_by_xpath(\"//i[@class='sd-icon sd-icon-next ']\").click()\n",
    "                                t.sleep(2)\n",
    "                            except NoSuchElementException:\n",
    "                                break\n",
    "                    except NoSuchElementException:\n",
    "                        pass\n",
    "                    d.close()\n",
    "                    d.switch_to.window(main_window)\n",
    "                    \n",
    "    return snap_revs, snap_rats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(sites, product):\n",
    "    urls = {'amazon':'https://www.amazon.in/',\n",
    "            'flipkart':'https://www.flipkart.com/',\n",
    "            'snapdeal':'https://www.snapdeal.com/',\n",
    "            'croma': 'https://www.croma.com/'}\n",
    "    products = [product]\n",
    "\n",
    "    revs = []\n",
    "    rats = []\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "\n",
    "    for site in sites:\n",
    "        d = get_drive_launch(urls[site])\n",
    "        if site.lower() == 'amazon':\n",
    "            reviews, ratings = scrape_amazon(d, products)\n",
    "        elif site.lower() == 'flipkart':\n",
    "            reviews, ratings = scrape_flipkart(d, products,1)\n",
    "        elif site.lower() == 'snapdeal':\n",
    "            reviews, ratings = scrape_snapdeal(d, products)\n",
    "        d.quit()\n",
    "        revs = revs + reviews\n",
    "        rats = rats + ratings\n",
    "    data = pd.DataFrame({'Reviews': revs, 'Ratings':rats})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites=['snapdeal','flipkart','amazon']\n",
    "#products = ['laptops', 'phones', 'headphones', 'smart watches', 'Professional Cameras', 'Printers', 'monitors', 'Home Theater', 'router']\n",
    "products = ['Home Theater', 'router']\n",
    "#sites=['snapdeal']\n",
    "#products = ['laptops']\n",
    "\n",
    "for product in products:\n",
    "    review_data = scrape_reviews(sites, product)\n",
    "    review_data.to_csv('./data/all_sites_'+product+'_reviews_data.csv', sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
